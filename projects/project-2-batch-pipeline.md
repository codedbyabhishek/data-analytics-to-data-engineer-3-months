# Project 2: Batch Data Pipeline

## Goal
Design and implement a resilient daily ETL pipeline from source files/API to a warehouse-ready model.

## Stack
- Python
- SQL
- Airflow or Prefect
- Postgres/BigQuery/Snowflake

## Scope
- Extract from at least two sources
- Transform into clean intermediate tables
- Load fact/dimension model
- Add pipeline logs and failure handling

## Deliverables
- Pipeline code with modular structure
- DAG/flow definition
- Data model diagram
- Runbook (how to run + troubleshoot)

## Evaluation Criteria
- Reliability and idempotency
- Code quality and modularity
- Data model correctness
